{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rfdavid/neural-network-playground/blob/master/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpvQSICUg7Y_"
      },
      "source": [
        "<h1>AlexNet Architecture</h1>\n",
        "\n",
        "This is the implementation of AlexNet on PyTorch using CIFAR-10 data.\n",
        "<a href=\"https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\" target=\"_blank\">https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf</a>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fipYiXN6PpcK"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "from collections import OrderedDict\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    # This structure was extracted from official PyTorch repository\n",
        "'''\n",
        "  (n + 2*p - f)/s + 1\n",
        "\n",
        "  n x n image (32x32)\n",
        "  f x f filter (kernel size)\n",
        "  p padding\n",
        "  s stride\n",
        "'''      \n",
        "    def __init__(self, num_classes):\n",
        "        super(Model, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size = 11, stride = 4, padding = 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2),\n",
        "            nn.Conv2d(64, 192, kernel_size = 5, padding = 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2),\n",
        "            nn.Conv2d(192, 384, kernel_size = 3, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(384, 256, kernel_size = 3, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size = 3, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2),\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "'''\n",
        "   The generic Neural Network class for MNIST dataset\n",
        "   methods:\n",
        "    - load_data()\n",
        "    - run()\n",
        "    - train()\n",
        "    - test()\n",
        "'''\n",
        "class NeuralNetwork():\n",
        "    def __init__(self, model = None, loss_fn = None, optimizer = None, debug = True):\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.debug = debug\n",
        "        self.train_dataloader = None\n",
        "        self.test_dataloader = None\n",
        "\n",
        "    def train(self):\n",
        "        correct = 0\n",
        "        size = len(self.train_dataloader.dataset)\n",
        "        for batch, (X, y) in enumerate(self.train_dataloader):\n",
        "            pred = self.model(X)\n",
        "            loss = self.loss_fn(pred, y)\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "        correct /= size\n",
        "        if self.debug:\n",
        "          print(f\"Training Accuracy: {(100*correct):>0.1f}%\")\n",
        "\n",
        "        return correct\n",
        "\n",
        "    def test(self):\n",
        "        size = len(self.test_dataloader.dataset)\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for  batch, (X, y) in enumerate(self.test_dataloader):\n",
        "                pred = self.model(X)\n",
        "                correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "        correct /= size\n",
        "        if self.debug:\n",
        "          print(f\"Test Accuracy: {(100*correct):>0.1f}%\")\n",
        "\n",
        "        return correct\n",
        "\n",
        "    def load_data(self, batch_size = 4):\n",
        "        transform = transforms.Compose(\n",
        "            [transforms.ToTensor(),\n",
        "            transforms.Resize((63,63))])\n",
        "\n",
        "        training_data = datasets.CIFAR10(\n",
        "            root='data',\n",
        "            train=True,\n",
        "            download=True,\n",
        "            transform=transform\n",
        "        )\n",
        "\n",
        "        test_data = datasets.CIFAR10(\n",
        "            root='data',\n",
        "            train=False,\n",
        "            download=True,\n",
        "            transform=transform\n",
        "        )\n",
        "\n",
        "        self.train_dataloader = DataLoader(training_data, batch_size = batch_size, shuffle = True)\n",
        "        self.test_dataloader = DataLoader(test_data, batch_size = batch_size)\n",
        "\n",
        "    def run(self, epochs):\n",
        "        for t in range(epochs):\n",
        "            print(f\"\\nEpoch {t+1}\")\n",
        "            print(\"-------\")\n",
        "            self.train()\n",
        "            self.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXgApWlvPyI_",
        "outputId": "80095d48-de47-4066-efb7-1cd857aa43b0"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "network = NeuralNetwork()\n",
        "network.model = Model(10).to(device)\n",
        "network.load_data()\n",
        "network.optimizer = torch.optim.SGD(network.model.parameters(), lr = 0.001, momentum = 0.9)\n",
        "network.loss_fn = nn.CrossEntropyLoss()\n",
        "network.run(epochs = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "Epoch 1\n",
            "-------\n",
            "Training Accuracy: 25.9%\n",
            "Test Accuracy: 45.5%\n",
            "\n",
            "Epoch 2\n",
            "-------\n",
            "Training Accuracy: 52.3%\n",
            "Test Accuracy: 59.5%\n",
            "\n",
            "Epoch 3\n",
            "-------\n",
            "Training Accuracy: 62.8%\n",
            "Test Accuracy: 62.7%\n",
            "\n",
            "Epoch 4\n",
            "-------\n",
            "Training Accuracy: 69.4%\n",
            "Test Accuracy: 68.4%\n",
            "\n",
            "Epoch 5\n",
            "-------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}